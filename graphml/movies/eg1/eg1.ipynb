{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "import torch_geometric\n",
    "from torch_geometric.nn.conv import MessagePassing\n",
    "from torch_geometric.utils import degree\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_name = ['place_index', 'user_index', 'rating']\n",
    "review_df = pd.read_csv(\"train.tsv\", sep=\"\\t\")[columns_name].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_user_id = review_df['user_index'].max()\n",
    "max_place_id = review_df['place_index'].max()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_node_id = max_user_id + max_place_id + 1 # since place_id starts from 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_test_split(review_df.values, test_size=0.1)\n",
    "train_df = pd.DataFrame(train, columns=review_df.columns)\n",
    "test_df = pd.DataFrame(test, columns=review_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.59525181 0.75159322 0.25561637 0.11561983 0.04555491]\n"
     ]
    }
   ],
   "source": [
    "# Weights will be used to normalize loss function\n",
    "def get_weights(df):\n",
    "    rating_counts = np.array([len(df[df['rating'] == i]) for i in [1, 2, 3, 4, 5]])\n",
    "    inverse_count = 1 / rating_counts\n",
    "    norm = np.linalg.norm(inverse_count)\n",
    "    normalized_inverse_count = inverse_count / norm\n",
    "\n",
    "    return normalized_inverse_count\n",
    "\n",
    "weights = get_weights(train_df)\n",
    "print(weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['weight'] = train_df['rating'].map(lambda val: weights[int(val)-1])\n",
    "test_df['weight'] = test_df['rating'].map(lambda val: weights[int(val)-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>place_index</th>\n",
       "      <th>user_index</th>\n",
       "      <th>rating</th>\n",
       "      <th>weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>185</td>\n",
       "      <td>46197</td>\n",
       "      <td>4</td>\n",
       "      <td>0.115620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4824</td>\n",
       "      <td>27755</td>\n",
       "      <td>5</td>\n",
       "      <td>0.045555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1092</td>\n",
       "      <td>1376</td>\n",
       "      <td>3</td>\n",
       "      <td>0.255616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4721</td>\n",
       "      <td>10935</td>\n",
       "      <td>4</td>\n",
       "      <td>0.115620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>852</td>\n",
       "      <td>16080</td>\n",
       "      <td>1</td>\n",
       "      <td>0.595252</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   place_index  user_index  rating    weight\n",
       "0          185       46197       4  0.115620\n",
       "1         4824       27755       5  0.045555\n",
       "2         1092        1376       3  0.255616\n",
       "3         4721       10935       4  0.115620\n",
       "4          852       16080       1  0.595252"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check data snippet\n",
    "train_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDataset(Dataset):\n",
    "    def __init__(self, data):\n",
    "        self.data = data.to_numpy()\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        return self.data[index, 0].astype(np.compat.long), \\\n",
    "            self.data[index, 1].astype(np.compat.long), \\\n",
    "            self.data[index, 2:3].astype(np.float32), \\\n",
    "            self.data[index, 3]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "u_t = torch.LongTensor(train_df.user_index.to_numpy())\n",
    "p_t = torch.LongTensor(train_df.place_index.to_numpy()) + max_user_id + 1\n",
    "\n",
    "train_edge_index = torch.stack((torch.cat([u_t, p_t]),torch.cat([p_t, u_t]))).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['place_index'] = train_df['place_index'] + max_user_id + 1\n",
    "test_df['place_index'] = test_df['place_index'] + max_user_id + 1\n",
    "# assert that there's no index overlapping\n",
    "intersection = set(train_df['place_index'].unique()).intersection(set(train_df['user_index'].unique()))\n",
    "assert len(intersection) == 0\n",
    "\n",
    "intersection = set(test_df['place_index'].unique()).intersection(set(test_df['user_index'].unique()))\n",
    "assert len(intersection) == 0\n",
    "\n",
    "train_dataset = MyDataset(train_df)\n",
    "test_dataset = MyDataset(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LightGCNConv(MessagePassing):\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__(aggr='add')\n",
    "\n",
    "    def forward(self, x, edge_index, num_nodes):\n",
    "        # Compute normalization\n",
    "        from_, to_ = edge_index\n",
    "        deg = degree(to_, x.size(0), dtype=x.dtype)\n",
    "        deg_inv_sqrt = deg.pow(-0.5)\n",
    "        deg_inv_sqrt[deg_inv_sqrt == float('inf')] = 0\n",
    "        norm = deg_inv_sqrt[from_] * deg_inv_sqrt[to_]\n",
    "        # Start propagating messages (no update after aggregation)\n",
    "        return self.propagate(edge_index, x=x, norm=norm)\n",
    "\n",
    "    def message(self, x_j, norm):\n",
    "        return norm.view(-1, 1) * x_j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0000, 0.0000, 0.7071, 0.5000, 0.0000],\n",
       "        [0.0000, 0.0000, 0.0000, 0.5000, 0.7071],\n",
       "        [0.7071, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.5000, 0.5000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.0000, 0.7071, 0.0000, 0.0000, 0.0000]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize node embeddings as one-hot embeddings\n",
    "test_x = torch.Tensor(np.eye(5))\n",
    "\n",
    "# Construct edges\n",
    "test_edge_index = torch.LongTensor(np.array([\n",
    "  [0, 0, 1, 1, 2, 3, 3, 4],\n",
    "  [2, 3, 3, 4, 0, 0, 1, 1]\n",
    "]))\n",
    "\n",
    "# Check out the result of passing the embeddings through our Graph Convolutional Network\n",
    "LightGCNConv()(test_x, test_edge_index, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LightGCN(nn.Module):\n",
    "    def __init__(self, latent_dim, num_layers, max_index):\n",
    "        super(LightGCN, self).__init__()\n",
    "        self.embedding = nn.Embedding(max_index, latent_dim)\n",
    "        self.convs = nn.ModuleList(LightGCNConv() for _ in range(num_layers))\n",
    "        self.init_parameters()\n",
    "        self.nn = nn.Linear(2*latent_dim, 1)\n",
    "\n",
    "        self.max_index = max_index\n",
    "\n",
    "    def init_parameters(self):\n",
    "        nn.init.normal_(self.embedding.weight, std=0.1) \n",
    "\n",
    "    def forward(self, edge_index):\n",
    "        emb0 = self.embedding.weight\n",
    "        embs = [emb0]\n",
    "        emb = emb0\n",
    "        for conv in self.convs:\n",
    "            emb = conv(x=emb, edge_index=edge_index, num_nodes=self.max_index)\n",
    "            embs.append(emb)\n",
    "\n",
    "        out = torch.mean(torch.stack(embs, dim=0), dim=0)\n",
    "        return emb0, out\n",
    "    \n",
    "    def pred(self, users, items, embeddings):\n",
    "        user_emb = embeddings[users]\n",
    "        item_emb = embeddings[items]\n",
    "        x = torch.cat((user_emb,item_emb), 1)\n",
    "        x = self.nn(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_dim = 64\n",
    "n_layers = 3 \n",
    "\n",
    "EPOCHS = 5\n",
    "BATCH_SIZE = 100\n",
    "DECAY = 0.0001\n",
    "LR = 0.005 \n",
    "K = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "lightgcn = LightGCN(\n",
    "    latent_dim=latent_dim,\n",
    "    num_layers=n_layers,\n",
    "    max_index=max_node_id + 1\n",
    ")\n",
    "lightgcn = lightgcn.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_testset_loss(model, testset, loss_fn, embeddings):\n",
    "    loss_list = []\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for items, users, ratings, weights in DataLoader(testset, batch_size=BATCH_SIZE):\n",
    "            users, items, ratings, weights = users.to(device), items.to(device), ratings.to(device), weights.to(device)\n",
    "            pred = model.pred(users, items, embeddings)\n",
    "            loss = loss_fn(pred, ratings, weights)\n",
    "            \n",
    "            loss_list.append(loss.item())\n",
    "            \n",
    "    return sum(loss_list) / len(loss_list)\n",
    "\n",
    "\n",
    "def train(model, optimizer, train_dataset, test_dataset, train_edge_index, loss_fn):\n",
    "    loss_list_epoch = []\n",
    "    valid_loss_list_epoch = []\n",
    "    train_dataloader = DataLoader(train_dataset, batch_size=BATCH_SIZE)\n",
    "    min_valid_loss = None\n",
    "    min_loss_model = None\n",
    "    for epoch in tqdm(range(EPOCHS)):\n",
    "        n_batch = int(len(train_dataset)/BATCH_SIZE)\n",
    "        loss_list = []\n",
    "        model.train()\n",
    "        for items, users, ratings, weights in tqdm(train_dataloader):\n",
    "            optimizer.zero_grad()\n",
    "            users, items, ratings, weights = users.to(device), items.to(device), ratings.to(device), weights.to(device)\n",
    "            _, embeddings = model(train_edge_index)\n",
    "            pred = model.pred(users, items, embeddings)\n",
    "            loss = loss_fn(pred, ratings, weights)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            loss_list.append(loss.item())\n",
    "            \n",
    "        # evaluate on validation data\n",
    "        valid_loss = get_testset_loss(model, test_dataset, loss_fn, embeddings)\n",
    "        if min_valid_loss is None or valid_loss < min_valid_loss:\n",
    "            min_valid_loss = valid_loss\n",
    "            min_loss_model = torch.save(model.state_dict(), f\"epoch_{epoch}.ckpt\")\n",
    "            \n",
    "        valid_loss_list_epoch.append(round(valid_loss, 4))\n",
    "        loss_list_epoch.append(round(np.mean(loss_list),4))\n",
    "\n",
    "    return loss_list_epoch, valid_loss_list_epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate weights of different labels and define weighted MSE loss\n",
    "def weighted_MSE(preds, targets, weights):\n",
    "    return (weights * (preds - targets) ** 2).mean()\n",
    "\n",
    "loss_function = weighted_MSE\n",
    "optimizer = torch.optim.Adam(lightgcn.parameters(), lr=LR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "00271f61531f445d9e86bfc4577ca8b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f430c166ce64911a31106bfb7daa964",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/11663 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[22], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m loss_history, valid_loss_history \u001b[39m=\u001b[39m train(lightgcn, optimizer, train_dataset, test_dataset, train_edge_index, loss_function)\n",
      "Cell \u001b[0;32mIn[20], line 28\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(model, optimizer, train_dataset, test_dataset, train_edge_index, loss_fn)\u001b[0m\n\u001b[1;32m     26\u001b[0m optimizer\u001b[39m.\u001b[39mzero_grad()\n\u001b[1;32m     27\u001b[0m users, items, ratings, weights \u001b[39m=\u001b[39m users\u001b[39m.\u001b[39mto(device), items\u001b[39m.\u001b[39mto(device), ratings\u001b[39m.\u001b[39mto(device), weights\u001b[39m.\u001b[39mto(device)\n\u001b[0;32m---> 28\u001b[0m _, embeddings \u001b[39m=\u001b[39m model(train_edge_index)\n\u001b[1;32m     29\u001b[0m pred \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mpred(users, items, embeddings)\n\u001b[1;32m     30\u001b[0m loss \u001b[39m=\u001b[39m loss_fn(pred, ratings, weights)\n",
      "File \u001b[0;32m~/miniconda3/envs/graph/lib/python3.11/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "Cell \u001b[0;32mIn[17], line 19\u001b[0m, in \u001b[0;36mLightGCN.forward\u001b[0;34m(self, edge_index)\u001b[0m\n\u001b[1;32m     17\u001b[0m emb \u001b[39m=\u001b[39m emb0\n\u001b[1;32m     18\u001b[0m \u001b[39mfor\u001b[39;00m conv \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconvs:\n\u001b[0;32m---> 19\u001b[0m     emb \u001b[39m=\u001b[39m conv(x\u001b[39m=\u001b[39;49memb, edge_index\u001b[39m=\u001b[39;49medge_index, num_nodes\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmax_index)\n\u001b[1;32m     20\u001b[0m     embs\u001b[39m.\u001b[39mappend(emb)\n\u001b[1;32m     22\u001b[0m out \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mmean(torch\u001b[39m.\u001b[39mstack(embs, dim\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m), dim\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/graph/lib/python3.11/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "Cell \u001b[0;32mIn[15], line 13\u001b[0m, in \u001b[0;36mLightGCNConv.forward\u001b[0;34m(self, x, edge_index, num_nodes)\u001b[0m\n\u001b[1;32m     11\u001b[0m norm \u001b[39m=\u001b[39m deg_inv_sqrt[from_] \u001b[39m*\u001b[39m deg_inv_sqrt[to_]\n\u001b[1;32m     12\u001b[0m \u001b[39m# Start propagating messages (no update after aggregation)\u001b[39;00m\n\u001b[0;32m---> 13\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpropagate(edge_index, x\u001b[39m=\u001b[39;49mx, norm\u001b[39m=\u001b[39;49mnorm)\n",
      "File \u001b[0;32m~/miniconda3/envs/graph/lib/python3.11/site-packages/torch_geometric/nn/conv/message_passing.py:484\u001b[0m, in \u001b[0;36mMessagePassing.propagate\u001b[0;34m(self, edge_index, size, **kwargs)\u001b[0m\n\u001b[1;32m    481\u001b[0m     \u001b[39mif\u001b[39;00m res \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    482\u001b[0m         aggr_kwargs \u001b[39m=\u001b[39m res[\u001b[39m0\u001b[39m] \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(res, \u001b[39mtuple\u001b[39m) \u001b[39melse\u001b[39;00m res\n\u001b[0;32m--> 484\u001b[0m out \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49maggregate(out, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49maggr_kwargs)\n\u001b[1;32m    486\u001b[0m \u001b[39mfor\u001b[39;00m hook \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_aggregate_forward_hooks\u001b[39m.\u001b[39mvalues():\n\u001b[1;32m    487\u001b[0m     res \u001b[39m=\u001b[39m hook(\u001b[39mself\u001b[39m, (aggr_kwargs, ), out)\n",
      "File \u001b[0;32m~/miniconda3/envs/graph/lib/python3.11/site-packages/torch_geometric/nn/conv/message_passing.py:608\u001b[0m, in \u001b[0;36mMessagePassing.aggregate\u001b[0;34m(self, inputs, index, ptr, dim_size)\u001b[0m\n\u001b[1;32m    595\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39maggregate\u001b[39m(\u001b[39mself\u001b[39m, inputs: Tensor, index: Tensor,\n\u001b[1;32m    596\u001b[0m               ptr: Optional[Tensor] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m    597\u001b[0m               dim_size: Optional[\u001b[39mint\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[1;32m    598\u001b[0m \u001b[39m    \u001b[39m\u001b[39mr\u001b[39m\u001b[39m\"\"\"Aggregates messages from neighbors as\u001b[39;00m\n\u001b[1;32m    599\u001b[0m \u001b[39m    :math:`\\bigoplus_{j \\in \\mathcal{N}(i)}`.\u001b[39;00m\n\u001b[1;32m    600\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    606\u001b[0m \u001b[39m    as specified in :meth:`__init__` by the :obj:`aggr` argument.\u001b[39;00m\n\u001b[1;32m    607\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 608\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49maggr_module(inputs, index, ptr\u001b[39m=\u001b[39;49mptr, dim_size\u001b[39m=\u001b[39;49mdim_size,\n\u001b[1;32m    609\u001b[0m                             dim\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnode_dim)\n",
      "File \u001b[0;32m~/miniconda3/envs/graph/lib/python3.11/site-packages/torch_geometric/nn/aggr/base.py:109\u001b[0m, in \u001b[0;36mAggregation.__call__\u001b[0;34m(self, x, index, ptr, dim_size, dim, **kwargs)\u001b[0m\n\u001b[1;32m    106\u001b[0m     dim_size \u001b[39m=\u001b[39m \u001b[39mint\u001b[39m(index\u001b[39m.\u001b[39mmax()) \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m \u001b[39mif\u001b[39;00m index\u001b[39m.\u001b[39mnumel() \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m \u001b[39melse\u001b[39;00m \u001b[39m0\u001b[39m\n\u001b[1;32m    108\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 109\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__call__\u001b[39;49m(x, index, ptr, dim_size, dim, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    110\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mIndexError\u001b[39;00m, \u001b[39mRuntimeError\u001b[39;00m) \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    111\u001b[0m     \u001b[39mif\u001b[39;00m index \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/envs/graph/lib/python3.11/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/miniconda3/envs/graph/lib/python3.11/site-packages/torch_geometric/nn/aggr/basic.py:21\u001b[0m, in \u001b[0;36mSumAggregation.forward\u001b[0;34m(self, x, index, ptr, dim_size, dim)\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x: Tensor, index: Optional[Tensor] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m     19\u001b[0m             ptr: Optional[Tensor] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m, dim_size: Optional[\u001b[39mint\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m     20\u001b[0m             dim: \u001b[39mint\u001b[39m \u001b[39m=\u001b[39m \u001b[39m-\u001b[39m\u001b[39m2\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[0;32m---> 21\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mreduce(x, index, ptr, dim_size, dim, reduce\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39msum\u001b[39;49m\u001b[39m'\u001b[39;49m)\n",
      "File \u001b[0;32m~/miniconda3/envs/graph/lib/python3.11/site-packages/torch_geometric/nn/aggr/base.py:155\u001b[0m, in \u001b[0;36mAggregation.reduce\u001b[0;34m(self, x, index, ptr, dim_size, dim, reduce)\u001b[0m\n\u001b[1;32m    152\u001b[0m     \u001b[39mreturn\u001b[39;00m segment(x, ptr, reduce\u001b[39m=\u001b[39mreduce)\n\u001b[1;32m    154\u001b[0m \u001b[39massert\u001b[39;00m index \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m--> 155\u001b[0m \u001b[39mreturn\u001b[39;00m scatter(x, index, dim, dim_size, reduce)\n",
      "File \u001b[0;32m~/miniconda3/envs/graph/lib/python3.11/site-packages/torch_geometric/utils/scatter.py:74\u001b[0m, in \u001b[0;36mscatter\u001b[0;34m(src, index, dim, dim_size, reduce)\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[39mif\u001b[39;00m reduce \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39msum\u001b[39m\u001b[39m'\u001b[39m \u001b[39mor\u001b[39;00m reduce \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39madd\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[1;32m     73\u001b[0m     index \u001b[39m=\u001b[39m broadcast(index, src, dim)\n\u001b[0;32m---> 74\u001b[0m     \u001b[39mreturn\u001b[39;00m src\u001b[39m.\u001b[39;49mnew_zeros(size)\u001b[39m.\u001b[39;49mscatter_add_(dim, index, src)\n\u001b[1;32m     76\u001b[0m \u001b[39mif\u001b[39;00m reduce \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mmean\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[1;32m     77\u001b[0m     count \u001b[39m=\u001b[39m src\u001b[39m.\u001b[39mnew_zeros(dim_size)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "loss_history, valid_loss_history = train(lightgcn, optimizer, train_dataset, test_dataset, train_edge_index, loss_function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch_list = [(i+1) for i in range(EPOCHS)]\n",
    "\n",
    "plt.plot(epoch_list, loss_history, label='Training Loss')\n",
    "plt.plot(epoch_list, valid_loss_history, label='Validation Loss')\n",
    "\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "graph",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
